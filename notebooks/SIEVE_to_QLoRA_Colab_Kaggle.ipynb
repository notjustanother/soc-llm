{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a24b13",
   "metadata": {},
   "source": [
    "# SIEVE → QLoRA (Colab + Kaggle Compatible)\n",
    "\n",
    "This notebook cleans SIEVE-style CSV logs, builds stratified splits, exports JSONL, fine-tunes an **Instruct LLM** with **QLoRA**, evaluates macro-F1, and (optionally) pushes your adapter/dataset to the **Hugging Face Hub**.\n",
    "\n",
    "**Works on**: Google Colab or Kaggle (or any GPU Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef3304",
   "metadata": {},
   "source": [
    "## 0. Environment Check & Installs\n",
    "The cells below detect Colab/Kaggle automatically and install compatible versions of the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform, subprocess, textwrap\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def in_kaggle():\n",
    "    return \"KAGGLE_URL_BASE\" in os.environ or \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "\n",
    "print(\"Colab:\", in_colab())\n",
    "print(\"Kaggle:\", in_kaggle())\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "# Install core deps (pin lightly for broad compatibility)\n",
    "%pip -q install -U datasets transformers accelerate peft trl bitsandbytes scikit-learn huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA status\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8943ab",
   "metadata": {},
   "source": [
    "## 1. Hugging Face Login (Optional but recommended)\n",
    "Login to access gated models, push adapters, and host private datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "DO_HF_LOGIN = True  # set False if you don't want to login right now\n",
    "if DO_HF_LOGIN:\n",
    "    try:\n",
    "        login()  # paste your token from https://huggingface.co/settings/tokens\n",
    "    except Exception as e:\n",
    "        print(\"HF login skipped or failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4da805",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion Options\n",
    "\n",
    "You have **three** ways to provide data:\n",
    "- **A. Upload files** (Colab: left sidebar \"Files\" → Upload, Kaggle: Add data).\n",
    "- **B. Mount Google Drive** (Colab only).\n",
    "- **C. Use Kaggle Dataset path** (Kaggle only).\n",
    "\n",
    "Set `DATA_MODE` and paths in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ==== Configure here ====\n",
    "DATA_MODE = \"UPLOAD\"  # \"UPLOAD\" | \"GDRIVE\" | \"KAGGLE\"\n",
    "\n",
    "# If using UPLOAD, place your CSV(s) in the working directory. Example:\n",
    "CSV_PATH = Path(\"2-cat-sample.csv\")   # change to your file name\n",
    "\n",
    "# If using Google Drive in Colab:\n",
    "GDRIVE_PATH = \"/content/drive/MyDrive/sieve_data/2-cat-sample.csv\"\n",
    "\n",
    "# If using Kaggle, attach dataset and set the path:\n",
    "KAGGLE_DATA_PATH = \"/kaggle/input/your-dataset-folder/2-cat-sample.csv\"\n",
    "\n",
    "# Output directory for all artifacts (JSONL, labels, checkpoints)\n",
    "OUT_DIR = Path(\"sieve_prepped\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def resolve_data_path():\n",
    "    if DATA_MODE == \"UPLOAD\":\n",
    "        return CSV_PATH\n",
    "    elif DATA_MODE == \"GDRIVE\":\n",
    "        return Path(GDRIVE_PATH)\n",
    "    elif DATA_MODE == \"KAGGLE\":\n",
    "        return Path(KAGGLE_DATA_PATH)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown DATA_MODE\")\n",
    "        \n",
    "data_path = resolve_data_path()\n",
    "print(\"Using data:\", data_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a777069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Mount Google Drive in Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    if DATA_MODE == \"GDRIVE\":\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"Drive mounted. Ensure GDRIVE_PATH points to your CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60049541",
   "metadata": {},
   "source": [
    "## 3. Robust CSV Loader for Mixed-Format Logs\n",
    "\n",
    "This loader:\n",
    "- Handles Apple Numbers \"Table 1\" wrappers\n",
    "- Joins extra columns back into the `log` text (keeps all data)\n",
    "- Produces a clean 2-column dataframe: `category` (label), `log` (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_sieve_csv(csv_path):\n",
    "    rows = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)\n",
    "        # Try to detect header names; otherwise assume first row is header-like\n",
    "        # Normalize common cases: category / log\n",
    "        def norm(x): return str(x).strip().lower()\n",
    "        category_idx, log_start = None, None\n",
    "\n",
    "        # If there's a header row with category/log\n",
    "        if header and any('category' in norm(h) for h in header) and any('log' in norm(h) for h in header):\n",
    "            # set indices\n",
    "            for i, h in enumerate(header):\n",
    "                if 'category' in norm(h) and category_idx is None:\n",
    "                    category_idx = i\n",
    "                if 'log' in norm(h) and log_start is None:\n",
    "                    log_start = i\n",
    "        else:\n",
    "            # No reliable header detected; assume first col = category, rest join as log\n",
    "            category_idx, log_start = 0, 1\n",
    "            # If the first row looks like real data, include it\n",
    "            if header:\n",
    "                if len(header) > 1:\n",
    "                    rows.append([header[0], \",\".join(header[1:]).strip()])\n",
    "                else:\n",
    "                    rows.append([None, \",\".join(header).strip()])\n",
    "\n",
    "        # Process remaining rows\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            if category_idx is not None and log_start is not None and log_start < len(row):\n",
    "                category = row[category_idx]\n",
    "                log = \",\".join(row[log_start:]).strip()\n",
    "            else:\n",
    "                # fallback: first cell is category, rest is log\n",
    "                category = row[0] if len(row) > 0 else None\n",
    "                log = \",\".join(row[1:]).strip() if len(row) > 1 else \"\"\n",
    "            rows.append([category, log])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"category\", \"log\"])\n",
    "    # Cleanup\n",
    "    df = df.dropna(subset=[\"category\", \"log\"])\n",
    "    df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
    "    df[\"log\"] = df[\"log\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    df = df.drop_duplicates(subset=[\"category\",\"log\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = load_sieve_csv(str(data_path))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10bb63",
   "metadata": {},
   "source": [
    "## 4. Normalize → `label`, `text` and Inspect Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"category\":\"label\", \"log\":\"text\"})\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821c385",
   "metadata": {},
   "source": [
    "## 5. Stratified Train/Val/Test Split\n",
    "Keeps the class ratio consistent across splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aac77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c79bab",
   "metadata": {},
   "source": [
    "## 6. Baseline: TF-IDF + LinearSVC (Sanity Check)\n",
    "If this is reasonably good (e.g., macro-F1 ≥ 0.7), your data is learnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2481605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "baseline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(lowercase=False, strip_accents=None, ngram_range=(1,2), min_df=1)),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "\n",
    "baseline.fit(train_df[\"text\"], train_df[\"label\"])\n",
    "val_pred = baseline.predict(val_df[\"text\"])\n",
    "test_pred = baseline.predict(test_df[\"text\"])\n",
    "\n",
    "print(\"Validation Report:\\n\", classification_report(val_df[\"label\"], val_pred, digits=4))\n",
    "print(\"Macro-F1 (Val):\", f1_score(val_df[\"label\"], val_pred, average=\"macro\"))\n",
    "print(\"Macro-F1 (Test):\", f1_score(test_df[\"label\"], test_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f410d",
   "metadata": {},
   "source": [
    "## 7. Export JSONL (Instruction + Classification) and labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"sieve_prepped\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def write_jsonl(df_in, path, mode=\"instruction\"):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, r in df_in.iterrows():\n",
    "            if mode == \"instruction\":\n",
    "                obj = {\n",
    "                    \"instruction\": \"Classify the SIEM event type for this log line.\",\n",
    "                    \"input\": r[\"text\"],\n",
    "                    \"output\": r[\"label\"]\n",
    "                }\n",
    "            else:\n",
    "                obj = {\"input\": r[\"text\"], \"label\": r[\"label\"]}\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "files = {\n",
    "    \"train_ins\": OUT_DIR / \"train.instruction.jsonl\",\n",
    "    \"val_ins\":   OUT_DIR / \"val.instruction.jsonl\",\n",
    "    \"test_ins\":  OUT_DIR / \"test.instruction.jsonl\",\n",
    "    \"train_cls\": OUT_DIR / \"train.classification.jsonl\",\n",
    "    \"val_cls\":   OUT_DIR / \"val.classification.jsonl\",\n",
    "    \"test_cls\":  OUT_DIR / \"test.classification.jsonl\",\n",
    "}\n",
    "\n",
    "write_jsonl(train_df, files[\"train_ins\"], \"instruction\")\n",
    "write_jsonl(val_df,   files[\"val_ins\"],   \"instruction\")\n",
    "write_jsonl(test_df,  files[\"test_ins\"],  \"instruction\")\n",
    "write_jsonl(train_df, files[\"train_cls\"], \"classification\")\n",
    "write_jsonl(val_df,   files[\"val_cls\"],   \"classification\")\n",
    "write_jsonl(test_df,  files[\"test_cls\"],  \"classification\")\n",
    "\n",
    "# labels.txt\n",
    "labels = sorted(df[\"label\"].unique())\n",
    "with open(OUT_DIR / \"labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for lab in labels:\n",
    "        f.write(lab + \"\\n\")\n",
    "\n",
    "print(\"Exported to:\", OUT_DIR.resolve())\n",
    "print(\"Labels:\", labels[:10], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451eaac",
   "metadata": {},
   "source": [
    "## 8. QLoRA Fine-Tuning (HF TRL + PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"  # change if needed\n",
    "MAX_SEQ_LEN = 1024\n",
    "EPOCHS = 3\n",
    "LR = 1e-4\n",
    "GRAD_ACCUM = 32\n",
    "PER_DEVICE_BATCH = 2\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "SEED = 42\n",
    "\n",
    "train_jsonl = str(Path(\"sieve_prepped\") / \"train.instruction.jsonl\")\n",
    "val_jsonl   = str(Path(\"sieve_prepped\") / \"val.instruction.jsonl\")\n",
    "test_jsonl  = str(Path(\"sieve_prepped\") / \"test.instruction.jsonl\")\n",
    "labels_txt  = str(Path(\"sieve_prepped\") / \"labels.txt\")\n",
    "\n",
    "raw_ds = load_dataset(\"json\", data_files={\"train\": train_jsonl, \"validation\": val_jsonl, \"test\": test_jsonl})\n",
    "\n",
    "def to_text(example):\n",
    "    return {\"text\": f\"Instruction: {example['instruction']}\\nInput: {example['input']}\\nAnswer: {example['output']}\"}\n",
    "\n",
    "ds = raw_ds.map(to_text, remove_columns=raw_ds[\"train\"].column_names)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_cfg = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, quantization_config=bnb_cfg, device_map=\"auto\")\n",
    "model.config.use_cache = False\n",
    "\n",
    "peft_cfg = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"up_proj\",\"down_proj\",\"gate_proj\"],\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "train_cfg = SFTConfig(\n",
    "    output_dir=\"sieve-llm-qlora\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    learning_rate=LR,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    bf16=True,\n",
    "    seed=SEED,\n",
    "    dataset_text_field=\"text\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    args=train_cfg\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"sieve-llm-qlora\")\n",
    "print(\"Saved QLoRA adapter to sieve-llm-qlora/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80a383",
   "metadata": {},
   "source": [
    "## 9. Validation: Constrained Mapping to Labels + Macro-F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "labels = [l.strip() for l in open(labels_txt, \"r\", encoding=\"utf-8\").read().splitlines()]\n",
    "\n",
    "gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"sieve-llm-qlora\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=8,\n",
    "    temperature=0.0,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "def classify_one(logline: str) -> str:\n",
    "    prompt = f\"Instruction: Classify the SIEM event type for this log line.\\nInput: {logline}\\nAnswer:\"\n",
    "    out = gen(prompt)[0][\"generated_text\"]\n",
    "    tail = out.split(\"Answer:\", 1)[-1].strip().lower()\n",
    "\n",
    "    # exact contains match\n",
    "    for lab in labels:\n",
    "        if lab.lower() in tail:\n",
    "            return lab\n",
    "\n",
    "    # token cleanup + fuzzy match\n",
    "    token = re.sub(r\"[^a-z0-9\\-]+\", \" \", tail).strip().split()\n",
    "    token = token[0] if token else \"\"\n",
    "    if token:\n",
    "        import difflib\n",
    "        guess = difflib.get_close_matches(token, [l.lower() for l in labels], n=1, cutoff=0.0)\n",
    "        if guess:\n",
    "            idx = [l.lower() for l in labels].index(guess[0])\n",
    "            return labels[idx]\n",
    "    return labels[0]  # fallback\n",
    "\n",
    "val_rows = [json.loads(l) for l in open(val_jsonl, \"r\", encoding=\"utf-8\").read().splitlines()]\n",
    "y_true = [r[\"output\"] for r in val_rows]\n",
    "y_pred = [classify_one(r[\"input\"]) for r in val_rows]\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"Macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be10c07",
   "metadata": {},
   "source": [
    "## 10. (Optional) Push Adapter & Dataset to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, upload_folder, HfApi\n",
    "\n",
    "PUSH_ADAPTER = False         # set True to push LoRA adapter\n",
    "PUSH_DATASET = False         # set True to push JSONL as a dataset\n",
    "HF_USERNAME = \"your-username\"  # change this\n",
    "\n",
    "if PUSH_ADAPTER:\n",
    "    adapter_repo = f\"{HF_USERNAME}/sieve-llm-qlora-adapter\"\n",
    "    create_repo(adapter_repo, private=True, exist_ok=True)\n",
    "    upload_folder(repo_id=adapter_repo, folder_path=\"sieve-llm-qlora\", path_in_repo=\".\")\n",
    "    print(\"Adapter pushed:\", f\"https://huggingface.co/{adapter_repo}\")\n",
    "\n",
    "if PUSH_DATASET:\n",
    "    ds_repo = f\"{HF_USERNAME}/sieve-2cat-jsonl\"\n",
    "    api = HfApi()\n",
    "    api.create_repo(ds_repo, repo_type=\"dataset\", private=True, exist_ok=True)\n",
    "    upload_folder(repo_id=ds_repo, repo_type=\"dataset\", folder_path=str(OUT_DIR), path_in_repo=\".\")\n",
    "    print(\"Dataset pushed:\", f\"https://huggingface.co/datasets/{ds_repo}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
