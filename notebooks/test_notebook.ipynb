{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4486682f",
   "metadata": {},
   "source": [
    "# SIEVE → QLoRA (Colab + Kaggle) with Google Drive Sync\n",
    "This notebook cleans SIEVE-style CSV logs, builds stratified splits, exports JSONL, fine-tunes an **Instruct LLM** with **QLoRA**, evaluates macro-F1, and supports Google Drive sync (Colab) and ZIP export (Kaggle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675335b8",
   "metadata": {},
   "source": [
    "## Verify the environment and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "def IN_COLAB():\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def IN_KAGGLE():\n",
    "    return \"KAGGLE_URL_BASE\" in os.environ or \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "\n",
    "print(\"Colab:\", IN_COLAB())\n",
    "print(\"Kaggle:\", IN_KAGGLE())\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "%pip -q install -U datasets transformers accelerate peft trl bitsandbytes scikit-learn huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663a450",
   "metadata": {},
   "source": [
    "## Cuda Status (Optional) may just rmove this has no real requirement during testing or production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08255553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA status\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300649b",
   "metadata": {},
   "source": [
    "## Setup Paths currently Data Storage and Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive sync (Colab) and paths\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"sieve_prepped\")\n",
    "CKPT_DIR = Path(\"sieve-llm-qlora\")\n",
    "\n",
    "if IN_COLAB():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = Path(\"/content/drive/MyDrive/Capstone/Training/Classification/sieve_prepped\")\n",
    "    CKPT_DIR = Path(\"/content/drive/MyDrive/Capstone/Training/Classification/sieve_checkpoints/sieve-llm-qlora\")\n",
    "elif IN_KAGGLE():\n",
    "    DATA_DIR = Path(\"/kaggle/working/sieve_prepped\")\n",
    "    CKPT_DIR = Path(\"/kaggle/working/sieve-llm-qlora\")\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"CKPT_DIR:\", CKPT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e262f0",
   "metadata": {},
   "source": [
    "# Pass Hugging Face Token to interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5aab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Hugging Face login\n",
    "from huggingface_hub import login\n",
    "DO_HF_LOGIN = True\n",
    "if DO_HF_LOGIN:\n",
    "    try:\n",
    "        login()\n",
    "    except Exception as e:\n",
    "        print(\"HF login skipped or failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a82cc8",
   "metadata": {},
   "source": [
    "## Load and verify CSV formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust CSV loader\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def load_sieve_csv(csv_path):\n",
    "    rows = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)\n",
    "        def norm(x): return str(x).strip().lower()\n",
    "        category_idx, log_start = None, None\n",
    "\n",
    "        if header and any('category' in norm(h) for h in header) and any('log' in norm(h) for h in header):\n",
    "            for i, h in enumerate(header):\n",
    "                if 'category' in norm(h) and category_idx is None:\n",
    "                    category_idx = i\n",
    "                if 'log' in norm(h) and log_start is None:\n",
    "                    log_start = i\n",
    "        else:\n",
    "            category_idx, log_start = 0, 1\n",
    "            if header:\n",
    "                if len(header) > 1:\n",
    "                    rows.append([header[0], \",\".join(header[1:]).strip()])\n",
    "                else:\n",
    "                    rows.append([None, \",\".join(header).strip()])\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            if category_idx is not None and log_start is not None and log_start < len(row):\n",
    "                category = row[category_idx]\n",
    "                log = \",\".join(row[log_start:]).strip()\n",
    "            else:\n",
    "                category = row[0] if len(row) > 0 else None\n",
    "                log = \",\".join(row[1:]).strip() if len(row) > 1 else \"\"\n",
    "            rows.append([category, log])\n",
    "    df = pd.DataFrame(rows, columns=[\"category\",\"log\"]).dropna(subset=[\"category\",\"log\"])\n",
    "    df[\"category\"] = df[\"category\"].astype(str).str.strip()\n",
    "    df[\"log\"] = df[\"log\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    df = df.drop_duplicates(subset=[\"category\",\"log\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = load_sieve_csv(str(CSV_PATH))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d11c0",
   "metadata": {},
   "source": [
    "## Verify and normalize CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49484967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"category\":\"label\", \"log\":\"text\"})\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555ee41",
   "metadata": {},
   "source": [
    "## Configurable Training Data Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b67f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split\n",
    "from sklearn.model_selection import train_test_split\n",
    "controlled_subset_df, _ = train_test_split(\n",
    "    df,\n",
    "    test_size=0.9,             # keep only 10 % for small_df\n",
    "    stratify=df[\"label\"],      # preserve label distribution\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Subset size: {len(controlled_subset_df)} ({len(controlled_subset_df)/len(df)*100:.1f}% of total)\")\n",
    "print(controlled_subset_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    controlled_subset_df, \n",
    "    test_size=0.2,          # 80/20 split for train vs temp\n",
    "    random_state=42, \n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, \n",
    "    test_size=0.5,              # half of temp → 10 % val, 10 % test (of subset)\n",
    "    random_state=42, \n",
    "    stratify=temp_df[\"label\"]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998594b",
   "metadata": {},
   "source": [
    "## Check if the dataset meets the minimum score for training (> 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaec5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "baseline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(lowercase=False, strip_accents=None, ngram_range=(1,2), min_df=1)),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "baseline.fit(train_df[\"text\"], train_df[\"label\"])\n",
    "val_pred = baseline.predict(val_df[\"text\"])\n",
    "test_pred = baseline.predict(test_df[\"text\"])\n",
    "print(\"Validation Report:\\n\", classification_report(val_df[\"label\"], val_pred, digits=4))\n",
    "print(\"Macro-F1 (Val):\", f1_score(val_df[\"label\"], val_pred, average=\"macro\"))\n",
    "print(\"Macro-F1 (Test):\", f1_score(test_df[\"label\"], test_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58ca01",
   "metadata": {},
   "source": [
    "## Export JSONL + labels.txt into DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write_jsonl(df_in, path, mode=\"instruction\"):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, r in df_in.iterrows():\n",
    "            if mode == \"instruction\":\n",
    "                obj = {\"instruction\":\"Classify the SIEM event type for this log line.\", \"input\":r[\"text\"], \"output\":r[\"label\"]}\n",
    "            else:\n",
    "                obj = {\"input\": r[\"text\"], \"label\": r[\"label\"]}\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "(files := {\n",
    "    \"train_ins\": DATA_DIR / \"train.instruction.jsonl\",\n",
    "    \"val_ins\":   DATA_DIR / \"val.instruction.jsonl\",\n",
    "    \"test_ins\":  DATA_DIR / \"test.instruction.jsonl\",\n",
    "    \"train_cls\": DATA_DIR / \"train.classification.jsonl\",\n",
    "    \"val_cls\":   DATA_DIR / \"val.classification.jsonl\",\n",
    "    \"test_cls\":  DATA_DIR / \"test.classification.jsonl\",\n",
    "})\n",
    "write_jsonl(train_df, files[\"train_ins\"], \"instruction\")\n",
    "write_jsonl(val_df,   files[\"val_ins\"],   \"instruction\")\n",
    "write_jsonl(test_df,  files[\"test_ins\"],  \"instruction\")\n",
    "write_jsonl(train_df, files[\"train_cls\"], \"classification\")\n",
    "write_jsonl(val_df,   files[\"val_cls\"],   \"classification\")\n",
    "write_jsonl(test_df,  files[\"test_cls\"],  \"classification\")\n",
    "\n",
    "labels = sorted(df[\"label\"].unique())\n",
    "with open(DATA_DIR / \"labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for lab in labels: f.write(lab + \"\\n\")\n",
    "\n",
    "print(\"Exported to:\", DATA_DIR.resolve())\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa47121",
   "metadata": {},
   "source": [
    "## QLoRA fine-tuning (saved to CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "MAX_SEQ_LEN = 512\n",
    "EPOCHS = 3\n",
    "LR = 1e-4\n",
    "GRAD_ACCUM = 64\n",
    "PER_DEVICE_BATCH = 1\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "SEED = 42\n",
    "\n",
    "train_jsonl = str(DATA_DIR / \"train.instruction.jsonl\")\n",
    "val_jsonl   = str(DATA_DIR / \"val.instruction.jsonl\")\n",
    "test_jsonl  = str(DATA_DIR / \"test.instruction.jsonl\")\n",
    "labels_txt  = str(DATA_DIR / \"labels.txt\")\n",
    "\n",
    "raw_ds = load_dataset(\"json\", data_files={\"train\": train_jsonl, \"validation\": val_jsonl, \"test\": test_jsonl})\n",
    "def to_text(ex): return {\"text\": f\"Instruction: {ex['instruction']}\\nInput: {ex['input']}\\nAnswer: {ex['output']}\"}\n",
    "ds = raw_ds.map(to_text, remove_columns=raw_ds[\"train\"].column_names)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
    "tok.model_max_length = MAX_SEQ_LEN\n",
    "\n",
    "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=\"bfloat16\")\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, quantization_config=bnb, device_map=\"auto\")\n",
    "model.config.use_cache = False\n",
    "\n",
    "peft_cfg = LoraConfig(r=LORA_R, lora_alpha=LORA_ALPHA, target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"up_proj\",\"down_proj\",\"gate_proj\"], lora_dropout=LORA_DROPOUT, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "#cfg = SFTConfig(output_dir=str(CKPT_DIR), num_train_epochs=EPOCHS, per_device_train_batch_size=PER_DEVICE_BATCH, gradient_accumulation_steps=GRAD_ACCUM, learning_rate=LR, logging_steps=50, eval_strategy=\"steps\", eval_steps=200, save_steps=200, bf16=True, seed=SEED, dataset_text_field=\"text\")\n",
    "\n",
    "# Memory-friendly config\n",
    "mf_cfg = SFTConfig(\n",
    "    output_dir=str(CKPT_DIR), num_train_epochs=EPOCHS, per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM, learning_rate=LR,\n",
    "    \n",
    "    fp16=True, bf16=False, optim=\"paged_adamw_8bit\", gradient_checkpointing=True, dataloader_num_workers=0, \n",
    "    dataloader_pin_memory=False,\n",
    "    \n",
    "    eval_strategy=\"no\", save_steps=800, save_total_limit=2, logging_steps=50, seed=SEED, dataset_text_field=\"text\"\n",
    ")\n",
    "\n",
    "# trainer = SFTTrainer(model=model, tokenizer=tok, train_dataset=ds[\"train\"], eval_dataset=ds[\"validation\"], args=cfg)\n",
    "trainer = SFTTrainer(model=model, train_dataset=ds[\"train\"], eval_dataset=None, args=mf_cfg)\n",
    "\n",
    "# To resume from a Drive checkpoint:\n",
    "# trainer.train(resume_from_checkpoint=str(CKPT_DIR / \"checkpoint-XXXX\"))\n",
    "trainer.train()\n",
    "trainer.save_model(str(CKPT_DIR))\n",
    "print(\"Saved QLoRA adapter to:\", CKPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bdd37",
   "metadata": {},
   "source": [
    "## Validation (macro-F1) with constrained mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "labels = [l.strip() for l in open(labels_txt, \"r\", encoding=\"utf-8\").read().splitlines()]\n",
    "gen = pipeline(\"text-generation\", model=str(CKPT_DIR), tokenizer=tok, max_new_tokens=8, temperature=0.0, do_sample=False)\n",
    "\n",
    "def classify_one(s: str) -> str:\n",
    "    out = gen(f\"Instruction: Classify the SIEM event type for this log line.\\nInput: {s}\\nAnswer:\")[0][\"generated_text\"]\n",
    "    tail = out.split(\"Answer:\", 1)[-1].strip().lower()\n",
    "    for lab in labels:\n",
    "        if lab.lower() in tail: return lab\n",
    "    token = re.sub(r\"[^a-z0-9\\-]+\", \" \", tail).strip().split()\n",
    "    token = token[0] if token else \"\"\n",
    "    if token:\n",
    "        import difflib\n",
    "        guess = difflib.get_close_matches(token, [l.lower() for l in labels], n=1, cutoff=0.0)\n",
    "        if guess:\n",
    "            idx = [l.lower() for l in labels].index(guess[0])\n",
    "            return labels[idx]\n",
    "    return labels[0]\n",
    "\n",
    "val_rows = [json.loads(l) for l in open(val_jsonl, \"r\", encoding=\"utf-8\").read().splitlines()]\n",
    "y_true = [r[\"output\"] for r in val_rows]\n",
    "y_pred = [classify_one(r[\"input\"]) for r in val_rows]\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"Macro-F1:\", f1_score(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d01b",
   "metadata": {},
   "source": [
    "## Kaggle: ZIP checkpoints for download; Colab: persists to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "zip_path = str(CKPT_DIR) + \".zip\"\n",
    "if os.path.exists(zip_path): os.remove(zip_path)\n",
    "shutil.make_archive(str(CKPT_DIR), 'zip', root_dir=str(CKPT_DIR))\n",
    "print(\"Created:\", zip_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
